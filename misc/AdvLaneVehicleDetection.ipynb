{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Detection & Vehicle Tracking Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to store camera calibration data\n",
    "class calibration():\n",
    "    def __init__(self, obj_pts, img_pts, shape):\n",
    "        self.ret, self.M, self.dist, self.rvecs, self.tvecs =\\\n",
    "        cv2.calibrateCamera(obj_pts, img_pts, shape, None, None)\n",
    "\n",
    "# Class to store perspective transform matrices\n",
    "class transform():\n",
    "    def __init__(self, src, dst):       \n",
    "        self.M = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        \n",
    "# Class to store lane detection data\n",
    "class lane():\n",
    "    def __init__(self):\n",
    "        self.detected = False\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.fit = None\n",
    "        \n",
    "# Class to store color and gradient feature extraction parameters\n",
    "class parameters():\n",
    "    def __init__(self):\n",
    "        self.spat_size = (32, 32)\n",
    "        self.hist_bins = 32\n",
    "        self.orient = 8\n",
    "        self.pxs_cell = (8, 8)\n",
    "        self.cells_block = (2, 2)\n",
    "\n",
    "# Class to store vehicle detection data\n",
    "class vehicle():\n",
    "    def __init__(self):\n",
    "        self.scaler = None\n",
    "        self.clf = None\n",
    "        self.heatmaps = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Class Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = np.float32([[685, 450], [1090, 720], [190, 720], [595, 450]])\n",
    "dst = np.float32([[990, 0], [990, 720], [290, 720], [290, 0]])\n",
    "trans = transform(src, dst)\n",
    "\n",
    "left = lane()\n",
    "right = lane()\n",
    "\n",
    "par = parameters()\n",
    "car = vehicle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding function\n",
    "def threshold(img, thresh):\n",
    "    binary = np.zeros_like(img)\n",
    "    binary[(img >= thresh[0]) & (img <= thresh[1])] = 1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "# Thresholded absolute Sobel gradient\n",
    "def grad_thresh(img, orient, ksize, thresh):\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img[:, :, 0], cv2.CV_64F, 1, 0, ksize))\n",
    "    \n",
    "    elif orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img[:, :, 0], cv2.CV_64F, 0, 1, ksize))\n",
    "    \n",
    "    scaled_sobel = np.uint8(abs_sobel*(255/np.max(abs_sobel)))\n",
    "    \n",
    "    return threshold(scaled_sobel, thresh)\n",
    "\n",
    "# Thresholded magnitude of Sobel gradient\n",
    "def mag_thresh(img, ksize, thresh):\n",
    "    sobelx = cv2.Sobel(img[:, :, 0], cv2.CV_64F, 1, 0, ksize)\n",
    "    sobely = cv2.Sobel(img[:, :, 0], cv2.CV_64F, 0, 1, ksize)\n",
    "    \n",
    "    mag_sobelxy = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    scaled_sobel = np.uint8(mag_sobelxy*(255/np.max(mag_sobelxy)))\n",
    "\n",
    "    return threshold(scaled_sobel, thresh)\n",
    "\n",
    "# Thresholded direction of Sobel gradient\n",
    "def dir_thresh(img, ksize, thresh):\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(img[:, :, 0], cv2.CV_64F, 1, 0, ksize))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(img[:, :, 0], cv2.CV_64F, 0, 1, ksize))\n",
    "    \n",
    "    dir_sobelxy = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    return threshold(dir_sobelxy, thresh)\n",
    "\n",
    "# Warp image perspective\n",
    "def warp(img, view):\n",
    "    # Warp image perspective into bird's eye view\n",
    "    if view == 'b':\n",
    "        warped = cv2.warpPerspective(img, trans.M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "    # Warp image perspective into driver's view\n",
    "    elif view == 'd':\n",
    "        warped = cv2.warpPerspective(img, trans.Minv, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped\n",
    "\n",
    "# Find initial lane locations\n",
    "def find_initial(img):\n",
    "    histogram = np.sum(img[int(img.shape[0]*(3/4)):, :], axis=0) \n",
    "    midpoint = histogram.shape[0]//2\n",
    "    \n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint \n",
    "\n",
    "    left.x, left.y = find_initial_sub(img, leftx_base)\n",
    "    right.x, right.y = find_initial_sub(img, rightx_base)\n",
    "    \n",
    "    left.fit = np.polyfit(left.y, left.x, 2)\n",
    "    right.fit = np.polyfit(right.y, right.x, 2)\n",
    "    \n",
    "    left.detected = True\n",
    "    right.detected = True\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Find initial lane locations - sub function\n",
    "def find_initial_sub(img, xbase):\n",
    "    num_windows = 9   \n",
    "    window_height = img.shape[0]//num_windows # 80\n",
    "    margin = 80\n",
    "    min_pix = 800\n",
    "    \n",
    "    non_zeroy = np.array(img.nonzero()[0])\n",
    "    non_zerox = np.array(img.nonzero()[1])\n",
    "    \n",
    "    lane_inds = []\n",
    "    shift = 0\n",
    "    \n",
    "    # Sliding window technique\n",
    "    for window in range(num_windows):\n",
    "        winy_low = img.shape[0] - (window + 1)*window_height # Window lower bound\n",
    "        winy_high = img.shape[0] - window*window_height # Window upper bound\n",
    "\n",
    "        winx_left = xbase - margin # Window left bound\n",
    "        winx_right = xbase + margin # Window right bound\n",
    "\n",
    "        lane_inds_cur = ((non_zeroy >= winy_low) & (non_zeroy < winy_high) &\\\n",
    "                          (non_zerox >= winx_left) & (non_zerox < winx_right)).nonzero()[0]\n",
    "\n",
    "        lane_inds.append(lane_inds_cur)\n",
    "        \n",
    "        # Center window on average of detected non-zero pixels\n",
    "        if len(lane_inds_cur) > min_pix:\n",
    "            xbase_new = np.int(np.mean(non_zerox[lane_inds_cur]))\n",
    "            shift = xbase_new - xbase\n",
    "            xbase = xbase_new\n",
    "        \n",
    "        # Shift window by previous amount\n",
    "        else:\n",
    "            xbase += shift\n",
    "        \n",
    "\n",
    "    lane_inds = np.concatenate(lane_inds)\n",
    "\n",
    "    return non_zerox[lane_inds], non_zeroy[lane_inds]\n",
    "\n",
    "# Find lane locations using margin around previous lane locations\n",
    "def find_next(img):\n",
    "    leftx, lefty = find_next_sub(img, left.fit)\n",
    "    rightx, righty = find_next_sub(img, right.fit)\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Check whether current lanes are within margin of previous lanes\n",
    "    if np.all([((left_fit[2] > left.fit[2]*0.8) & (left_fit[2] < left.fit[2]*1.2)),\\\n",
    "               ((right_fit[2] > right.fit[2]*0.8) & (right_fit[2] < right.fit[2]*1.2))]):\n",
    "        \n",
    "        # Compute weighted average of current and previous polynomial coefficients\n",
    "        # based on number of non-zero pixels detected\n",
    "        left_weights = np.array([(len(leftx)/(len(leftx) + len(left.x))),\\\n",
    "                                 (len(left.x)/(len(leftx) + len(left.x)))])\n",
    "\n",
    "        right_weights = np.array([(len(rightx)/(len(rightx) + len(right.x))),\\\n",
    "                                 (len(right.x)/(len(rightx) + len(right.x)))])\n",
    "\n",
    "        left.fit = np.average((left_fit, left.fit), axis = 0, weights = left_weights)\n",
    "        right.fit = np.average((right_fit, right.fit), axis = 0, weights = right_weights)\n",
    "\n",
    "        left.x, left.y = leftx, lefty\n",
    "        right.x, right.y = rightx, righty\n",
    "    \n",
    "    # If current lanes outside of margin of previous lanes detect lanes from scratch\n",
    "    else:\n",
    "        find_initial(img)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def find_next_sub(img, fit):\n",
    "    margin = 80\n",
    "    \n",
    "    non_zeroy = np.array(img.nonzero()[0])\n",
    "    non_zerox = np.array(img.nonzero()[1])\n",
    "    \n",
    "    # Detect non-zero pixels within previously computed polynomial +/- margin\n",
    "    lane_inds = ((non_zerox > (fit[0]*(non_zeroy**2) + fit[1]*non_zeroy + fit[2] - margin)) &\\\n",
    "                 (non_zerox < (fit[0]*(non_zeroy**2) + fit[1]*non_zeroy + fit[2] + margin)))\n",
    "    \n",
    "    return non_zerox[lane_inds], non_zeroy[lane_inds]\n",
    "\n",
    "# Calculate road curvature radius and vehicle relation to lane center\n",
    "def info(shape):\n",
    "    \n",
    "    # Lane base x-points\n",
    "    leftx_base = np.mean(left.x[(left.y >= shape[0]*(3/4))])\n",
    "    rightx_base = np.mean(right.x[(right.y >= shape[0]*(3/4))]) \n",
    "    \n",
    "    # Pixel to meter conversion factors\n",
    "    xconv = 3.7/(rightx_base - leftx_base)\n",
    "    yconv = 30/720\n",
    "    \n",
    "    # Lane polynomial coefficients\n",
    "    left_fit = np.polyfit(left.y*yconv, left.x*xconv, 2)\n",
    "    right_fit = np.polyfit(right.y*yconv, right.x*xconv, 2)\n",
    "    \n",
    "    # Average of lane polynomial coefficients\n",
    "    fit = np.mean((left_fit, right_fit), axis = 0)\n",
    "    \n",
    "    # Road curvature radius\n",
    "    curve_rad = (((1 + (2*fit[0]*shape[0]*yconv + fit[1])**2)**1.5)/np.absolute(2*fit[0]))\n",
    "    \n",
    "    # Vehicle relation to lane center\n",
    "    off_center = (shape[1]/2 - np.mean((leftx_base, rightx_base)))*xconv\n",
    "    \n",
    "    return curve_rad, off_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spatial binning feature vector\n",
    "def get_spat_feat(img):\n",
    "    return cv2.resize(img, dsize=par.spat_size).ravel() \n",
    "\n",
    "# Compute color histogram feature vector\n",
    "def get_hist_feat(img):\n",
    "    hist_feat = []\n",
    "    # Compute histogram for each color channel\n",
    "    for channel in np.arange(img.shape[2]):\n",
    "        hist_feat.append(np.histogram(img[:,:,channel], bins=par.hist_bins)[0])\n",
    "    return np.concatenate(hist_feat)\n",
    "\n",
    "# Compute HOG feature vector\n",
    "def get_hog_feat(img, feat_vec):\n",
    "    hog_feat = []\n",
    "    # Compute HOG for each color channel\n",
    "    for channel in np.arange(img.shape[2]):\n",
    "        hog_feat.append(hog(img[:,:,channel], orientations=par.orient, pixels_per_cell=par.pxs_cell,\n",
    "                            cells_per_block=par.cells_block, visualise=False, transform_sqrt=True,\n",
    "                            feature_vector=feat_vec))\n",
    "    if feat_vec == True:\n",
    "        return np.concatenate(hog_feat)\n",
    "    else: return hog_feat\n",
    "\n",
    "# Extract feature vectors from images\n",
    "def extract_feat(fnames):\n",
    "    features = []\n",
    "    for file in fnames:\n",
    "        img = mpimg.imread(file)\n",
    "        # Convert image to YCrCb color space\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        spat_feat = get_spat_feat(img)\n",
    "        hist_feat = get_hist_feat(img)\n",
    "        hog_feat = get_hog_feat(img, feat_vec=True)\n",
    "        # Combine feature vectors\n",
    "        features.append(np.concatenate((spat_feat, hist_feat, hog_feat)))\n",
    "    return features\n",
    "\n",
    "# Find car bounding boxes\n",
    "def find_cars(img, ystart, ystop, scale):\n",
    "    # Crop image\n",
    "    img = img[ystart:ystop,:,:]\n",
    "    \n",
    "    # Convert image to YCrCb color space\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    \n",
    "    # Scale image\n",
    "    if scale != 1:\n",
    "        img = cv2.resize(img, (np.int(img.shape[1]/scale), np.int(img.shape[0]/scale)))\n",
    "    \n",
    "    # Compute number of HOG cells in x and y directions\n",
    "    xcells = (img.shape[1]//par.pxs_cell[0])\n",
    "    ycells = (img.shape[0]//par.pxs_cell[0])\n",
    "    \n",
    "    # Training dataset image size\n",
    "    window = 64\n",
    "    \n",
    "    # Compute number of HOG cells and blocks in window\n",
    "    cells_window = (window//par.pxs_cell[0])\n",
    "    block_steps = cells_window - par.cells_block[0] + 1\n",
    "    \n",
    "    # Compute number of steps in x and y directions\n",
    "    cells_step = 1\n",
    "    xsteps = (xcells - cells_window)//cells_step\n",
    "    ysteps = (ycells - cells_window)//cells_step\n",
    "    \n",
    "    hog = get_hog_feat(img, feat_vec = False)\n",
    "    \n",
    "    bbox_list = []\n",
    "    for xb in np.arange(xsteps):\n",
    "        for yb in np.arange(ysteps):\n",
    "            # Search window top left coordinate points in cell units\n",
    "            ypos = yb*cells_step\n",
    "            xpos = xb*cells_step\n",
    "            \n",
    "            # Within search window extract HOG subsample feature vector for each color channel\n",
    "            hog_feat = []\n",
    "            for channel in np.arange(img.shape[2]):\n",
    "                hog_feat.append(hog[channel][ypos:ypos+block_steps, xpos:xpos+block_steps])\n",
    "            hog_feat = np.concatenate(hog_feat).ravel()\n",
    "    \n",
    "            # Search window top left coordinate points in pixel units\n",
    "            xleft = xpos*par.pxs_cell[0]\n",
    "            ytop = ypos*par.pxs_cell[0]\n",
    "            \n",
    "            # Create search window\n",
    "            sub_img = cv2.resize(img[ytop:ytop+window, xleft:xleft+window], (window, window))\n",
    "            \n",
    "            spat_feat = get_spat_feat(sub_img)\n",
    "            hist_feat = get_hist_feat(sub_img)\n",
    "            \n",
    "            # Combine and scale feature vectors\n",
    "            features = np.concatenate((spat_feat, hist_feat, hog_feat))\n",
    "            scaled_features = car.scaler.transform(features)\n",
    "            \n",
    "            # Predict class and save confidence\n",
    "            confidence = car.clf.decision_function(scaled_features)\n",
    "            \n",
    "            # Save search window coordinate points\n",
    "            if confidence > 0.5:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                bbox_list.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart))) \n",
    "    return bbox_list\n",
    "\n",
    "# Create heatmap from bounding boxes\n",
    "def create_heatmap(heatmap, bbox_list):\n",
    "    for bbox in bbox_list:\n",
    "        heatmap[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]] += 1\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw identified lane and road information on image\n",
    "def draw_lane(img):\n",
    "    # Create blank canvas to draw lane on\n",
    "    blank = np.zeros_like(img).astype(np.uint8)\n",
    "    \n",
    "    # Create y-points\n",
    "    ploty = np.linspace(0, blank.shape[0] - 1, blank.shape[0])\n",
    "    \n",
    "    # Compute x-points\n",
    "    leftx = left.fit[0]*ploty**2 + left.fit[1]*ploty + left.fit[2]\n",
    "    rightx = right.fit[0]*ploty**2 + right.fit[1]*ploty + right.fit[2]\n",
    "    \n",
    "    # Combine lane points\n",
    "    left_pts = np.array([np.transpose(np.vstack([leftx, ploty]))])\n",
    "    right_pts = np.array([np.flipud(np.transpose(np.vstack([rightx, ploty])))])\n",
    "    pts = np.hstack((left_pts, right_pts))\n",
    "    \n",
    "    # Draw lane\n",
    "    lane = cv2.fillPoly(blank, np.int_([pts]), (0, 255, 0))\n",
    "    \n",
    "    # Project lane onto road\n",
    "    projected = warp(lane, view = 'd')\n",
    "    \n",
    "    # Combine image with projected lane\n",
    "    return cv2.addWeighted(img, 1, projected, 0.3, 0)\n",
    "    \n",
    "# Draw road curvature radius and vehicle relation to lane center on image\n",
    "def draw_info(img):\n",
    "    curve_rad, off_center = info(img.shape)\n",
    "    \n",
    "    curve_text = 'Curvature radius = {:d}m'.format(int(curve_rad))\n",
    "    \n",
    "    if off_center < 0:\n",
    "        off_text = 'Vehicle {:.2f}m left of center'.format(abs(off_center))\n",
    "    \n",
    "    elif off_center > 0:\n",
    "        off_text = 'Vehicle {:.2f}m right of center'.format(abs(off_center))\n",
    "\n",
    "    # Draw curvature radius on image\n",
    "    cv2.putText(img, curve_text, org = (10, 30), fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale = 1, thickness = 2, color = (0, 255, 0), bottomLeftOrigin = False)\n",
    "    \n",
    "    # Draw vehicle relation to lane center on image\n",
    "    return cv2.putText(img, off_text, org = (10, 60), fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       fontScale = 1, thickness = 2, color = (0, 255, 0), bottomLeftOrigin = False)\n",
    "\n",
    "def draw_bbox(img, cars):\n",
    "    # Draw bounding box for each car\n",
    "    for car in np.arange(1, cars[1] + 1):\n",
    "        non_zerox = (cars[0] == car).nonzero()[1]\n",
    "        non_zeroy = (cars[0] == car).nonzero()[0]\n",
    "        bbox = (np.min(non_zerox), np.min(non_zeroy)), (np.max(non_zerox), np.max(non_zeroy))\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,256), 4)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load calibration image filenames\n",
    "calibration_fnames = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "numx = 9 # Number of inner row corners\n",
    "numy = 6 # Number of inner column corners\n",
    "\n",
    "cal_obj_pts = []\n",
    "cal_img_pts = []\n",
    "\n",
    "# Create array of known object points\n",
    "obj_pts = np.zeros((numx*numy, 3), np.float32)\n",
    "obj_pts[:, :2] = np.mgrid[0:numx, 0:numy].T.reshape(-1, 2)\n",
    "\n",
    "# Loop over calibration images\n",
    "for fname in calibration_fnames:\n",
    "    img = mpimg.imread(fname) # Load image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # Convert image to grayscale\n",
    "    ret, img_pts = cv2.findChessboardCorners(gray, (numx, numy), None) # Detect image points\n",
    "    \n",
    "    # If chessboard corners detected, append object and image points to those previously detected\n",
    "    if ret == True: \n",
    "        cal_obj_pts.append(obj_pts)\n",
    "        cal_img_pts.append(img_pts)\n",
    "\n",
    "# Create an instance of the camera calibration data class\n",
    "cal = calibration(cal_obj_pts, cal_img_pts, img.shape[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Standardizing features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(2, 0)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4409cb131a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Standardize features by zero mean centering and scaling to standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mscaled_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peps/.conda/envs/carnd-term1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peps/.conda/envs/carnd-term1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    582\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peps/.conda/envs/carnd-term1/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    422\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 424\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(2, 0)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# Load car and non-car image filenames\n",
    "car_fnames = glob.glob('training_data/vehicles/vehicle*.jpg')\n",
    "non_car_fnames = glob.glob('training_data/non_vehicles/non_vehicle*.jpg')\n",
    "\n",
    "print('Extracting features...')\n",
    "\n",
    "# Extract color and gradient features from car and non-car images\n",
    "car_feat = extract_feat(car_fnames)\n",
    "non_car_feat = extract_feat(non_car_fnames)\n",
    "\n",
    "# Combine car and non-car features\n",
    "X = np.vstack((car_feat, non_car_feat)).astype(np.float64)\n",
    "\n",
    "print('Standardizing features...')\n",
    "\n",
    "# Standardize features by zero mean centering and scaling to standard deviation\n",
    "car.scaler = StandardScaler().fit(X)\n",
    "scaled_X = car.scaler.transform(X)\n",
    "\n",
    "# Create labels for car and non-car features\n",
    "y = np.hstack((np.ones(len(car_feat), dtype = np.int8), np.zeros(len(non_car_feat), dtype = np.int8)))\n",
    "\n",
    "print('Creating training and test subsets...')\n",
    "\n",
    "# Randomly split features and labels into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2,\n",
    "                                                    random_state=np.random.randint(0, 100))\n",
    "\n",
    "print('Number of training examples = ', len(X_train))\n",
    "print('Number of test examples = ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Linear SVC classifier\n",
    "car.clf = LinearSVC()\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "start = time.time()\n",
    "car.clf.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "\n",
    "print('Training Time = {:.3f} s'.format(stop - start))\n",
    "print('Training Accuracy = {:.3f}'.format(car.clf.score(X_train, y_train)))\n",
    "print('Test Accuracy = {:.3f}'.format(car.clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_pipeline(img):    \n",
    "    # Threshold image\n",
    "    binary_gradx = grad_thresh(img, orient = 'x', ksize = 3, thresh = (20, 255))\n",
    "    binary_grady = grad_thresh(img, orient = 'y', ksize = 3, thresh = (20, 255))\n",
    "    \n",
    "    binary_grad_mag = mag_thresh(img, ksize = 3, thresh = (40, 255))\n",
    "    binary_grad_dir = dir_thresh(img, ksize = 3, thresh = (0.7, 1.3))\n",
    "    \n",
    "    binary_rch = threshold(img[:, :, 0], thresh = (140, 255))\n",
    "    binary_sch = threshold(cv2.cvtColor(img, cv2.COLOR_RGB2HLS)[:, :, 2],\\\n",
    "                           thresh = (100, 255))\n",
    "    \n",
    "    # Combine binary images\n",
    "    combined = np.zeros_like(binary_gradx)\n",
    "    combined[((binary_gradx == 1) & (binary_grady == 1)) |\\\n",
    "                ((binary_grad_mag == 1) & (binary_grad_dir == 1)) |\\\n",
    "                ((binary_rch == 1) & (binary_sch == 1))] = 1\n",
    "    \n",
    "    # Warp image perspective into bird's eye view\n",
    "    warped = warp(combined, view = 'b')\n",
    "    \n",
    "    # Find lane locations from scratch\n",
    "    if left.detected == False & right.detected == False:\n",
    "        find_initial(warped)\n",
    "    \n",
    "    # Find lane locations using margin around previously found lane locations\n",
    "    elif left.detected == True & right.detected == True:\n",
    "        find_next(warped)\n",
    "   \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_pipeline(img):\n",
    "    # Parameters\n",
    "    ystart_list = [400, 400]\n",
    "    ystop_list = [480, 528]\n",
    "    scale_list = [1.25, 1.5]\n",
    "    thresh = 4\n",
    "    frames = 4\n",
    "    \n",
    "    # Find car bounding boxes\n",
    "    bbox_list = [] \n",
    "    for ystart, ystop, scale in zip(ystart_list, ystop_list, scale_list):\n",
    "        bbox = find_cars(img, ystart, ystop, scale)\n",
    "        if len(bbox) > 0:\n",
    "            bbox_list.append(bbox)\n",
    "\n",
    "    # Create a heatmap if bounding boxes were found\n",
    "    if len(bbox_list) > 0:\n",
    "        bbox_list = np.concatenate(bbox_list)\n",
    "        car.heatmaps.append(create_heatmap(np.zeros_like(img[:,:,0]), bbox_list))\n",
    "    \n",
    "    # Combine last n stored heatmaps\n",
    "    heatmap = np.zeros_like(img[:,:,0])\n",
    "    for i in range(len(car.heatmaps)):\n",
    "        heatmap += car.heatmaps[i]\n",
    "    \n",
    "    # Delete first in n stored heatmaps\n",
    "    if len(car.heatmaps) > frames:\n",
    "        del car.heatmaps[0]\n",
    "    \n",
    "    # Threshold heatmap\n",
    "    heatmap[heatmap < thresh] = 0\n",
    "\n",
    "    # Label individual heatmap regions\n",
    "    return label(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    \n",
    "    # Undistort image using previously computed camera calibration matrix\n",
    "    img = cv2.undistort(img, cal.M, cal.dist, None, cal.M)\n",
    "    \n",
    "    # Detect lane\n",
    "    lane_pipeline(img)\n",
    "    \n",
    "    # Detect vehicles\n",
    "    cars = vehicle_pipeline(img)\n",
    "    \n",
    "    # Draw lane, info, and bounding boxes\n",
    "    lane = draw_lane(img)\n",
    "    info = draw_info(lane)    \n",
    "    return draw_bbox(info, cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "car.heatmaps = []\n",
    "video_output = 'videos/output/project_video.mp4'\n",
    "video_input = VideoFileClip('videos/input/project_video.mp4')\n",
    "video_clip = video_input.fl_image(pipeline)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
